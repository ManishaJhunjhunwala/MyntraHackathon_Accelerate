# -*- coding: utf-8 -*-
"""MyntraHackathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ej-GbghoEfsR79N0XtyXjEPhvdY2qLIy

#Creators - Surbhi Sharma, Manisha Jhunjhunwala, Ayushi Sharma
#The code has been created with an intention of previewing the entire project
#Any suggestions or contributions are welcomed!!!

#The code takes a video file as input and suggests similar apparels from provided database as output

Added all paths
"""

path_lead_artist = '/content/FashionSearch/lead_artist'
path_video_file = '/content/FashionSearch/input.mp4'
path_model1 = '/content/FashionSearch/model/binaryfas10.json'
path_model2 = '/content/FashionSearch/model/binaryfashion.h5'
path_annotation = '/content/FashionSearch/annotation.csv'
path_result = '/content/FashionSearch/data/test'
path_download = '/content/FashionSearch/downloads'
modelName = 'resnet50'
path_data = '/content/FashionSearch/data/'
path_resnet50 = '/content/FashionSearch/data/output/resnet50'
print("Variables and Paths initialized")

"""All required imports"""

!pip install tensorflow

# Update pip
!python -m pip install -U pip

# Install scikit-image
!python -m pip install -U scikit-image
!python -c 'from skimage.data import download_all; download_all()'

#Some required library imports
import skimage
import skimage.io
import os, shutil
import cv2
import math
import numpy as np
import sys
import pandas as pd
import matplotlib.pyplot as plt
import imutils
import argparse
import datetime
import tensorflow as tf
from skimage.transform import resize
from sklearn.neighbors import NearestNeighbors
from matplotlib import offsetbox
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from sklearn import manifold

#module keras import
import keras
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten,Dropout
from keras.models import model_from_json
from keras.applications.resnet50 import ResNet50
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
from keras.preprocessing.image import save_img
print("All imports added")


"""Code to clear the existing images in folder"""

#clear source folder
folder = path_lead_artist
for filename in os.listdir(folder):
    file_path = os.path.join(folder, filename)
    try:
        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)
        elif os.path.isdir(file_path):
            shutil.rmtree(file_path)
    except Exception as e:
        print('Failed to delete %s. Reason: %s' % (file_path, e))

print("Source cleared..!!")

#clear destination folder
folder = path_result
for filename in os.listdir(folder):
    file_path = os.path.join(folder, filename)
    try:
        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)
        elif os.path.isdir(file_path):
            shutil.rmtree(file_path)
    except Exception as e:
        print('Failed to delete %s. Reason: %s' % (file_path, e))

print("Destination cleared..!!")

#clear output folder
folder = path_resnet50
for filename in os.listdir(folder):
    file_path = os.path.join(folder, filename)
    try:
        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)
        elif os.path.isdir(file_path):
            shutil.rmtree(file_path)
    except Exception as e:
        print('Failed to delete %s. Reason: %s' % (file_path, e))

print("Output cleared..!!")

"""Code to capture images from video and save in a folder"""

vidcap = cv2.VideoCapture(path_video_file)

def getFrame(sec):
    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)
    hasFrames,image = vidcap.read()
    if hasFrames:
        cv2.imwrite(path_lead_artist+"/image"+str(count)+".jpg", image)     # save frame as JPG file
    return hasFrames

frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)
fps = int(vidcap.get(cv2.CAP_PROP_FPS))
# calculate dusration of the video
seconds = int(frames / fps)
video_time = str(datetime.timedelta(seconds=seconds))
print("Duration of video (in seconds) :", seconds)
print("Video time:", video_time)


sec = 0
frameRate = 9 #//it will capture image in each 9 second
count=1
success = getFrame(sec)
while sec <= seconds:
  count = count + 1
  sec = sec + frameRate
  sec = round(sec, 2)
  success = getFrame(sec)
print ("Images extracted from Video clip..!!")

"""Code to extract clothes from the images extracted"""

def predictor(img_file,image_path):
	#print(img_file)
	image_path = path_lead_artist + "/"+img_file
	img = cv2.imread(image_path)
	#print(img)
	cv2.imwrite("test.jpg",img)
	resize = cv2.resize(img,(64,64))
	#resize = np.expand_dims(resize,axis=0)
	img_fin = np.reshape(resize,[1,64,64,3])
	json_file = open(path_model1, 'r')
	loaded_model_json = json_file.read()
	json_file.close()
	loaded_model = model_from_json(loaded_model_json)
	loaded_model.load_weights(path_model2)
	#print("Loaded model from disk")
	prediction = loaded_model.predict_classes(img_fin)
	prediction = np.squeeze(prediction,axis=1)
	predict = np.squeeze(prediction,axis=0)
	return int(predict)

def bg_elimination(img_file,image_path):
    predict = predictor(img_file,image_path)
    file = path_annotation
    reader = pd.read_csv(file)
    #print(predict)
    img = cv2.imread(image_path)
    img = cv2.resize(img,(300,500))
    #seg = image(image,reader.x1[predict],reader.y1[predict],reader.x2[predict],reader.y2[predict],reader.i[predict])
    mask = np.zeros(img.shape[:2],np.uint8)   
    bgdModel = np.zeros((1,65),np.float64)
    fgdModel = np.zeros((1,65),np.float64)
    rect = (reader.x1[predict],reader.y1[predict],reader.x2[predict],reader.y2[predict])
    cv2.grabCut(img,mask,rect,bgdModel,fgdModel,reader.i[predict],cv2.GC_INIT_WITH_RECT)
    mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')
    img_cut = img*mask2[:,:,np.newaxis]
    cv2.imwrite(path_result + "/back_"+str(img_file),img_cut)

for img_file in os.listdir(path_lead_artist):
	image_path= path_lead_artist + "/"+img_file
	bg_elimination(img_file,image_path)

	# define the upper and lower boundaries of the HSV pixel intensities to be considered 'skin'
	lower = np.array([0, 48, 80], dtype = "uint8")
	upper = np.array([20, 255, 255], dtype = "uint8")


	# grab the current frame
	frame=cv2.imread(path_result + "/back_"+str(img_file))
	fr=cv2.imread(path_result + "/back_"+str(img_file))
	fr = imutils.resize(fr, width = 400)
	# if we are viewing a video and we did not grab a frame, then we have reached the end of the video


	# resize the frame, convert it to the HSV color space, and determine the HSV pixel intensities that fall into the speicifed upper and lower boundaries
	frame = imutils.resize(frame, width = 400)
	converted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
	skinMask = cv2.inRange(converted, lower, upper)

	# apply a series of erosions and dilations to the mask using an elliptical kernel
	#print("\n",img_file)
	kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))
	skinMask = cv2.erode(skinMask, kernel, iterations = 2)
	skinMask = cv2.dilate(skinMask, kernel, iterations = 2)

	# blur the mask to help remove noise, then apply the mask to the frame
	skinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)
	#print(fr.size,skinMask.size,frame.size)
	cloth = cv2.bitwise_not(skinMask)
	
	#only_cloth = cv2.bitwise_and(frame, frame, mask = cloth)
	#cv2.imwrite(path_result + "/cloth_"+str(img_file),only_cloth)

	#cv2.imwrite(path_result + "/skin_"+str(img_file),cloth)
	# show the skin in the image along with the mask
	#cv2.imwrite(path_result + "/stack_"+str(img_file), np.hstack([frame, only_cloth]))
	# cleanup the camera and close any open windows

print("Image extraction complete")


"""Similarity Model"""

"""Transform Utils"""

# Apply transformations to multiple images
def apply_transformer(imgs, transformer, parallel=True):
    
    imgs_transform = [transformer(img) for img in imgs]
    return imgs_transform

# Normalize image data [0, 255] -> [0.0, 1.0]
def normalize_img(img):
    return img / 255.

# Resize image
def resize_img(img, shape_resized):
    img_resized = resize(img, shape_resized,
                         anti_aliasing=True,
                         preserve_range=True)
    assert img_resized.shape == shape_resized
    return img_resized

# Flatten image
def flatten_img(img):
    return img.flatten("C")

print("Transform Utils ready")

"""Plot Utils"""

# Plot image
def plot_img(img, range=[0, 255]):
    plt.imshow(img, vmin=range[0], vmax=range[1])
    plt.xlabel("xpixels")
    plt.ylabel("ypixels")
    plt.tight_layout()
    plt.show()
    plt.close()

# Plots images in 2 rows: top row is query, bottom row is answer
def plot_query_retrieval(img_query, imgs_retrieval, outFile):
    n_retrieval = len(imgs_retrieval)
    fig = plt.figure(figsize=(2*n_retrieval, 4))
    fig.suptitle("Image Retrieval (k={})".format(n_retrieval), fontsize=25)

    # Plot query image
    ax = plt.subplot(2, n_retrieval, 0 + 1)
    plt.imshow(img_query)
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
    for axis in ['top', 'bottom', 'left', 'right']:
        ax.spines[axis].set_linewidth(4)  # increase border thickness
        ax.spines[axis].set_color('black')  # set to black
    ax.set_title("query",  fontsize=14)  # set subplot title

    # Plot retrieval images
    for i, img in enumerate(imgs_retrieval):
        ax = plt.subplot(2, n_retrieval, n_retrieval + i + 1)
        plt.imshow(img)
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)
        for axis in ['top', 'bottom', 'left', 'right']:
            ax.spines[axis].set_linewidth(1)  # set border thickness
            ax.spines[axis].set_color('black')  # set to black
        ax.set_title("Rank #%d" % (i+1), fontsize=14)  # set subplot title

    if outFile is None:
        plt.show()
    else:
        plt.savefig(outFile, bbox_inches='tight')
    plt.close()

# Plot t-SNE of images
def plot_tsne(X, imgs, outFile):

    def imscatter(x, y, images, ax=None, zoom=1.0):
        if ax is None:
            ax = plt.gca()
        x, y = np.atleast_1d(x, y)
        artists = []
        for x0, y0, img0 in zip(x, y, images):
            im = OffsetImage(img0, zoom=zoom)
            ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=True)
            artists.append(ax.add_artist(ab))
        ax.update_datalim(np.column_stack([x, y]))
        ax.autoscale()
        return artists

    def plot_embedding(X, imgs, title=None):
        x_min, x_max = np.min(X, 0), np.max(X, 0)
        X = (X - x_min) / (x_max - x_min)

        plt.figure()
        ax = plt.subplot(111)
        for i in range(X.shape[0]):
            plt.text(X[i, 0], X[i, 1], ".", fontdict={'weight': 'bold', 'size': 9})
        if hasattr(offsetbox, 'AnnotationBbox'):
            imscatter(X[:,0], X[:,1], imgs, zoom=0.3, ax=ax)

        plt.xticks([]), plt.yticks([])
        if title is not None:
            plt.title(title, fontsize=18)

    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)
    X_tsne = tsne.fit_transform(X)
    plot_embedding(X_tsne, imgs, "t-SNE embeddings")
    if outFile is None:
        plt.show()
    else:
        plt.savefig(outFile, bbox_inches='tight')
    plt.close()

# Plot image reconstructions
def plot_reconstructions(imgs, imgs_reconstruct, outFile,
                         range_imgs=[0, 255],
                         range_imgs_reconstruct=[0, 1]):
    # Create plot to save
    assert len(imgs) == len(imgs_reconstruct)
    fig = plt.figure(figsize=(20, 4))
    fig.suptitle("Image Reconstructions", fontsize=35)
    n = min(len(imgs), 10)
    for i in range(n):

        # Plot original image
        ax = plt.subplot(2, n, i + 1)
        plt.imshow(imgs[i],
                   vmin=range_imgs[0],
                   vmax=range_imgs[1])
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

        # Plot reconstructed image
        ax = plt.subplot(2, n, n + i + 1)
        plt.imshow(imgs_reconstruct[i],
                   vmin=range_imgs_reconstruct[0],
                   vmax=range_imgs_reconstruct[1])
        ax.get_xaxis().set_visible(False)
        ax.get_yaxis().set_visible(False)

    if outFile is None:
        plt.show()
    else:
        plt.savefig(outFile, bbox_inches='tight')
    plt.close()

print("Plot Utils ready")

"""IO Utils"""

# Read image
def read_img(filePath):
    return skimage.io.imread(filePath, as_gray=False)

# Read images with common extensions from a directory
def read_imgs_dir(dirPath, extensions):
    args = [os.path.join(dirPath, filename)
            for filename in os.listdir(dirPath)
            if any(filename.lower().endswith(ext) for ext in extensions)]
    
    imgs = [read_img(arg) for arg in args]
    return imgs

# Save image to file
def save_img(filePath, img):
    skimage.io.imsave(filePath, img)

print("IO Utils ready")

""" Similarity Model """

# Class for Applying transformations to all images
class ImageTransformer(object):

    def __init__(self, shape_resize):
        self.shape_resize = shape_resize

    def __call__(self, img):
        img_transformed = resize_img(img, self.shape_resize)
        img_transformed = normalize_img(img_transformed)
        return img_transformed

#taking input on number of similar images to be retreived
n=int(input("Number of similar images to be retreived: "))

# Make paths
DataTrain = os.path.join(path_data, "train")
DataTest = os.path.join(path_data, "test")
outDir = os.path.join(path_data, "output", modelName)


#creating path for output images
if not os.path.exists(outDir):
    os.makedirs(outDir)


# Read images
extensions = [".jpg", ".jpeg"]
print("Reading train images from '{}'...".format(DataTrain))
imgs_train = read_imgs_dir(DataTrain, extensions)
print("Reading test images from '{}'...".format(DataTest))
imgs_test = read_imgs_dir(DataTest, extensions)
shape_img = imgs_train[0].shape
print("Image shape = {}".format(shape_img))

#downloading resnet50 with imagenet weights
print("Loading resnet pre-trained model...")
model = ResNet50(weights='imagenet',include_top=False,input_shape=shape_img)
#print(model.summary())


shape_img_resize = tuple([int(x) for x in model.input.shape[1:]])
input_shape_model = tuple([int(x) for x in model.input.shape[1:]])
output_shape_model = tuple([int(x) for x in model.output.shape[1:]])

# Print some model info
print("input_shape_model = {}".format(input_shape_model))
print("output_shape_model = {}".format(output_shape_model))
print("shape_img_resize = {}".format(shape_img_resize))


transformer = ImageTransformer(shape_img_resize)
print("Applying image transformer to training images...")
imgs_train_transformed = apply_transformer(imgs_train, transformer)
print("Applying image transformer to test images...")
imgs_test_transformed = apply_transformer(imgs_test, transformer)

# Convert images to numpy array
X_train = np.array(imgs_train_transformed).reshape((-1,) + input_shape_model)
X_test = np.array(imgs_test_transformed).reshape((-1,) + input_shape_model)
print(" -> X_train.shape = {}".format(X_train.shape))
print(" -> X_test.shape = {}".format(X_test.shape))

# Create embeddings using model
print("Inferencing embeddings using pre-trained model...")
E_train = model.predict(X_train)
E_train_flatten = E_train.reshape((-1, np.prod(output_shape_model)))
E_test = model.predict(X_test)
E_test_flatten = E_test.reshape((-1, np.prod(output_shape_model)))
print(" -> E_train.shape = {}".format(E_train.shape))
print(" -> E_test.shape = {}".format(E_test.shape))
print(" -> E_train_flatten.shape = {}".format(E_train_flatten.shape))
print(" -> E_test_flatten.shape = {}".format(E_test_flatten.shape))

#Fitting k-nearest neighbour model on training images
print("Fitting k-nearest-neighbour model on training images...")
knn = NearestNeighbors(n_neighbors=n, metric="cosine")
knn.fit(E_train_flatten)

#Find k nearest neighbours and retrieve images
for i, emb_flatten in enumerate(E_test_flatten):
    _, indices = knn.kneighbors([emb_flatten])# find k nearest train neighbours
    #print(indices)
    img_query = imgs_test[i] # query image
    imgs_retrieval = [imgs_train[idx] for idx in indices.flatten()] # retrieval images
    print(type(imgs_retrieval))

    for j, img in enumerate(imgs_retrieval):
      #print(type(img))
      #print(img.dtype)
      img_array = img_to_array(img)
      #print(type(img_array))
      #print(img_array.dtype)
      retrievalFile = os.path.join(outDir, "{}_retrieval_{}.png".format(i,j))
      save_img(retrievalFile, img_array)
    outFile = os.path.join(outDir, "{}_retrieval_{}.png".format(modelName, i))
    #plot_query_retrieval(img_query, imgs_retrieval, outFile=None)
    plot_query_retrieval(img_query, imgs_retrieval, outFile)
    print("Similar images result saved on output folder")
